{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4624d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c4aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments = pd.read_csv(\"../data/full_comments.csv\")\n",
    "examples = full_comments.loc[full_comments['true_label'].notna(), [\"comment_text\", \"true_label\"]].sample(10)\n",
    "negative_examples = pd.read_excel(\"negative_examples.xlsx\", names=['comment_text', 'original_label', 'corrected_label'])\n",
    "\n",
    "examples = examples.rename(columns={\"comment_text\": \"comment\", \"true_label\": \"label\"})\n",
    "\n",
    "examples_json = json.dumps(examples.to_dict(orient=\"records\"), indent=2)\n",
    "\n",
    "negative_examples_json = json.dumps(negative_examples.to_dict(orient=\"records\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0f0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = full_comments.sample(30000, random_state=10)\n",
    "\n",
    "indices = [a for a in full_comments.index if a not in subset.index]\n",
    "\n",
    "subset = full_comments.loc[indices, :]\n",
    "\n",
    "subset['label'] = subset['true_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "104ba741",
   "metadata": {},
   "outputs": [],
   "source": [
    "half = int(subset.shape[0] / 2)\n",
    "subset1 = subset[:half]\n",
    "subset2 = subset[half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e596b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENT_COLUMN = \"comment_text\"\n",
    "OUTPUT_CSV = \"claude_comments_labeled.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b3ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get('ANTHROPIC_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454c58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "MODEL = \"claude-haiku-4-5-20251001\"\n",
    "BATCH_SIZE = 30\n",
    "BATCH_ID_FILE = \"batch_id.txt\"\n",
    "\n",
    "# SYSTEM PROMPT\n",
    "SYSTEM_PROMPT = f\"\"\"You are a comment classifier. You will be given a batch of comments, each with an ID number. \n",
    "Classify each comment into exactly ONE of these five categories:\n",
    "\n",
    "**Argumentative**\n",
    "- Makes specific claims, predictions, or assertions supported by reasoning\n",
    "- Uses evidence, anecdotes, or scenarios to build a case\n",
    "- The key distinction from Opinion: there's an attempt to *persuade* or *explain why*, not just state a position\n",
    "\n",
    "**Informational**\n",
    "- Shares facts, data, links, or context relevant to the discussion\n",
    "- Low emotional affect — the comment is trying to *inform*, not convince or react\n",
    "- Includes answering another commenter's question with factual content\n",
    "- The key distinction from Argumentative: presenting information without advocating for a position\n",
    "\n",
    "**Opinion**\n",
    "- States a value judgment, stance, or take without substantial reasoning\n",
    "- \"This is good/bad/wrong/overrated\" — the comment *asserts* but doesn't *argue*\n",
    "- The key distinction from Argumentative: no real attempt to persuade or support the claim\n",
    "- The key distinction from Expressive: the comment is making a point, not just reacting\n",
    "\n",
    "**Expressive**\n",
    "- Emotional reactions, sarcasm, jokes, venting, exclamations\n",
    "- The comment is primarily *expressing feeling* rather than making a point\n",
    "- Includes performative agreement/disagreement (\"THIS,\" \"lol exactly,\" \"what a joke\")\n",
    "- The key distinction from Opinion: no identifiable stance being taken, just affect\n",
    "\n",
    "**Neutral**\n",
    "- Clarifying or rhetorical questions, meta-commentary, off-topic remarks\n",
    "- Comments that don't clearly fit the other four categories\n",
    "- Includes simple factual questions directed at other commenters\n",
    "\n",
    "**Correctly labeled examples** — these demonstrate the correct label for each comment:\n",
    "{examples_json}\n",
    "\n",
    "**Incorrectly labeled examples** — these were originally mislabeled. The \"original_label\" is the wrong label that was assigned, and the \"corrected_label\" is what the label should have been. Use these to understand common mistakes to avoid:\n",
    "{negative_examples_json}\n",
    "\n",
    "Respond with ONLY a valid JSON array where each element has \"id\", \"label\" keys and a confidence indicator where \n",
    "0 is not confident in the chosen label and 1 is confident in the chosen label.\n",
    "Example: [{{\"id\": 0, \"label\": \"Argumentative\", \"confidence\": 1}}, {{\"id\": 1, \"label\": \"Expressive\", \"confidence\": 0}}]\n",
    "\n",
    "Do not include any text outside the JSON array. No explanations, no markdown.\"\"\"\n",
    "\n",
    "VALID_LABELS = {\"Argumentative\", \"Informational\", \"Opinion\", \"Expressive\", \"Neutral\"}\n",
    "\n",
    "def format_batch(comments):\n",
    "    lines = []\n",
    "    for idx, comment in comments:\n",
    "        truncated = comment[:1500] if len(comment) > 1500 else comment\n",
    "        lines.append(f\"[{idx}] {truncated}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "def parse_response(response_text, expected_ids):\n",
    "    text = response_text.strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.split(\"\\n\", 1)[1]\n",
    "        text = text.rsplit(\"```\", 1)[0]\n",
    "\n",
    "    try:\n",
    "        results = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            results = ast.literal_eval(text)\n",
    "        except (ValueError, SyntaxError):\n",
    "            match = re.search(r'\\[.*\\]', text, re.DOTALL)\n",
    "            if match:\n",
    "                try:\n",
    "                    results = json.loads(match.group())\n",
    "                except json.JSONDecodeError:\n",
    "                    return {}\n",
    "            else:\n",
    "                return {}\n",
    "\n",
    "    if results and isinstance(results[0], list):\n",
    "        results = results[0]\n",
    "\n",
    "    labels = {}\n",
    "    for item in results:\n",
    "        idx = item.get(\"id\")\n",
    "        label = item.get(\"label\", \"\").strip()\n",
    "        conf = item.get(\"confidence\", \"\")\n",
    "        if idx not in expected_ids:\n",
    "            continue\n",
    "        if label not in VALID_LABELS:\n",
    "            matched = [v for v in VALID_LABELS if v.lower() == label.lower()]\n",
    "            if matched:\n",
    "                label = matched[0]\n",
    "            else:\n",
    "                continue\n",
    "        labels[idx] = {\"label\": label, \"confidence\": conf}\n",
    "    return labels\n",
    "\n",
    "def save_results(df):\n",
    "    if os.path.exists(OUTPUT_CSV):\n",
    "        existing = pd.read_csv(OUTPUT_CSV)\n",
    "        combined = pd.concat([existing, df], ignore_index=True)\n",
    "    else:\n",
    "        combined = df\n",
    "    combined.to_csv(OUTPUT_CSV, index=False)\n",
    "    return combined\n",
    "\n",
    "client = Anthropic(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7790b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47649 comments to label\n",
      "1589 requests created\n",
      "Batch submitted! ID: msgbatch_01WR5aRbJBcFd8np754HqS6C\n",
      "Saved batch_id to batch_id.txt and mapping to batch_mapping.json\n",
      "You can close your computer now.\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Build requests and submit batch\n",
    "\n",
    "df = subset.copy()\n",
    "\n",
    "# Build batches of comments\n",
    "unlabeled_mask = df[\"label\"].isna()\n",
    "unlabeled_indices = df[unlabeled_mask].index.tolist()\n",
    "print(f\"{len(unlabeled_indices)} comments to label\")\n",
    "\n",
    "batches = []\n",
    "for i in range(0, len(unlabeled_indices), BATCH_SIZE):\n",
    "    batch_indices = unlabeled_indices[i:i + BATCH_SIZE]\n",
    "    batch = [(idx, str(df.loc[idx, COMMENT_COLUMN])) for idx in batch_indices]\n",
    "    batches.append(batch)\n",
    "\n",
    "# Save mapping of batch index -> expected IDs for retrieval later\n",
    "batch_mapping = {}\n",
    "requests = []\n",
    "for i, batch in enumerate(batches):\n",
    "    expected_ids = [idx for idx, _ in batch]\n",
    "    batch_mapping[str(i)] = expected_ids\n",
    "    requests.append({\n",
    "        \"custom_id\": f\"batch_{i}\",\n",
    "        \"params\": {\n",
    "            \"model\": MODEL,\n",
    "            \"max_tokens\": 2048,\n",
    "            \"system\": SYSTEM_PROMPT,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": format_batch(batch)}]\n",
    "        }\n",
    "    })\n",
    "\n",
    "print(f\"{len(requests)} requests created\")\n",
    "\n",
    "# Submit\n",
    "batch_job = client.messages.batches.create(requests=requests)\n",
    "batch_id = batch_job.id\n",
    "\n",
    "# Save batch_id and mapping so results can be retrieved after restart\n",
    "with open(BATCH_ID_FILE, \"w\") as f:\n",
    "    f.write(batch_id)\n",
    "\n",
    "with open(\"batch_mapping.json\", \"w\") as f:\n",
    "    json.dump(batch_mapping, f)\n",
    "\n",
    "print(f\"Batch submitted! ID: {batch_id}\")\n",
    "print(f\"Saved batch_id to {BATCH_ID_FILE} and mapping to batch_mapping.json\")\n",
    "print(\"You can close your computer now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b2npljl3h4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: ended\n",
      "Counts: MessageBatchRequestCounts(canceled=0, errored=0, expired=0, processing=0, succeeded=1589)\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Check batch status (run when you come back)\n",
    "with open(BATCH_ID_FILE, \"r\") as f:\n",
    "    batch_id = f.read().strip()\n",
    "\n",
    "status = client.messages.batches.retrieve(batch_id)\n",
    "print(f\"Status: {status.processing_status}\")\n",
    "print(f\"Counts: {status.request_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ykb5q61r3j",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE — 47614 comments labeled, 0 batches failed\n",
      "Saved to: claude_comments_labeled.csv (47714 total rows)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "Opinion          16492\n",
      "Expressive       13026\n",
      "Argumentative    10342\n",
      "Neutral           4709\n",
      "Informational     3110\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Retrieve results and save (run once status is \"ended\")\n",
    "with open(BATCH_ID_FILE, \"r\") as f:\n",
    "    batch_id = f.read().strip()\n",
    "\n",
    "with open(\"batch_mapping.json\", \"r\") as f:\n",
    "    batch_mapping = json.load(f)\n",
    "\n",
    "df = subset.copy()\n",
    "total_labeled = 0\n",
    "failed = 0\n",
    "\n",
    "for result in client.messages.batches.results(batch_id):\n",
    "    # Extract batch index from custom_id (e.g. \"batch_0\" -> \"0\")\n",
    "    batch_idx = result.custom_id.split(\"_\")[1]\n",
    "    expected_ids = batch_mapping[batch_idx]\n",
    "\n",
    "    if result.result.type == \"succeeded\":\n",
    "        response_text = result.result.message.content[0].text\n",
    "        labels = parse_response(response_text, expected_ids)\n",
    "\n",
    "        for idx, value in labels.items():\n",
    "            df.loc[idx, \"label\"] = value[\"label\"]\n",
    "            df.loc[idx, \"confidence\"] = value[\"confidence\"]\n",
    "\n",
    "        total_labeled += len(labels)\n",
    "    else:\n",
    "        failed += 1\n",
    "        print(f\"  Batch {batch_idx} failed: {result.result.type}\")\n",
    "\n",
    "combined = save_results(df)\n",
    "\n",
    "print(f\"\\nDONE — {total_labeled} comments labeled, {failed} batches failed\")\n",
    "print(f\"Saved to: {OUTPUT_CSV} ({len(combined)} total rows)\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df[\"label\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02dd2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"comments_labeled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS-509_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
