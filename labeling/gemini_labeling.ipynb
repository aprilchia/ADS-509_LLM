{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments = pd.read_csv(\"../data/full_comments.csv\")\n",
    "examples = full_comments.loc[full_comments['true_label'].notna(), [\"comment_text\", \"true_label\"]].sample(10)\n",
    "negative_examples = pd.read_excel(\"negative_examples.xlsx\", names=['comment_text', 'original_label', 'corrected_label'])\n",
    "\n",
    "examples = examples.rename(columns={\"comment_text\": \"comment\", \"true_label\": \"label\"})\n",
    "\n",
    "examples_json = json.dumps(examples.to_dict(orient=\"records\"), indent=2)\n",
    "negative_examples_json = json.dumps(negative_examples.to_dict(orient=\"records\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = full_comments.sample(30000, random_state=10)\n",
    "\n",
    "indices = [a for a in full_comments.index if a not in subset.index]\n",
    "\n",
    "subset = full_comments.loc[indices, :]\n",
    "\n",
    "subset['label'] = subset['true_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "half = int(subset.shape[0] / 2)\n",
    "subset1 = subset[:half]\n",
    "subset2 = subset[half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENT_COLUMN = \"comment_text\"\n",
    "OUTPUT_CSV = \"gemini_comments_labeled_p1.csv\"\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ.get('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "MODEL = \"models/gemini-3-flash-preview\"\n",
    "BATCH_SIZE = 50\n",
    "MAX_REQUESTS_PER_JOB = 100\n",
    "JOB_NAMES_FILE = \"gemini_job_names.json\"\n",
    "\n",
    "# ============================================================\n",
    "# SYSTEM PROMPT\n",
    "# ============================================================\n",
    "SYSTEM_PROMPT = f\"\"\"You are a comment classifier. You will be given a batch of comments, each with an ID number. \n",
    "Classify each comment into exactly ONE of these five categories:\n",
    "\n",
    "**Argumentative**\n",
    "- Makes specific claims, predictions, or assertions supported by reasoning\n",
    "- Uses evidence, anecdotes, or scenarios to build a case\n",
    "- The key distinction from Opinion: there's an attempt to *persuade* or *explain why*, not just state a position\n",
    "\n",
    "**Informational**\n",
    "- Shares facts, data, links, or context relevant to the discussion\n",
    "- Low emotional affect — the comment is trying to *inform*, not convince or react\n",
    "- Includes answering another commenter's question with factual content\n",
    "- The key distinction from Argumentative: presenting information without advocating for a position\n",
    "\n",
    "**Opinion**\n",
    "- States a value judgment, stance, or take without substantial reasoning\n",
    "- \"This is good/bad/wrong/overrated\" — the comment *asserts* but doesn't *argue*\n",
    "- The key distinction from Argumentative: no real attempt to persuade or support the claim\n",
    "- The key distinction from Expressive: the comment is making a point, not just reacting\n",
    "\n",
    "**Expressive**\n",
    "- Emotional reactions, sarcasm, jokes, venting, exclamations\n",
    "- The comment is primarily *expressing feeling* rather than making a point\n",
    "- Includes performative agreement/disagreement (\"THIS,\" \"lol exactly,\" \"what a joke\")\n",
    "- The key distinction from Opinion: no identifiable stance being taken, just affect\n",
    "\n",
    "**Neutral**\n",
    "- Clarifying or rhetorical questions, meta-commentary, off-topic remarks\n",
    "- Comments that don't clearly fit the other four categories\n",
    "- Includes simple factual questions directed at other commenters\n",
    "\n",
    "**Correctly labeled examples** — these demonstrate the correct label for each comment:\n",
    "{examples_json}\n",
    "\n",
    "**Incorrectly labeled examples** — these were originally mislabeled. The \"original_label\" is the wrong label that was assigned, and the \"corrected_label\" is what the label should have been. Use these to understand common mistakes to avoid:\n",
    "{negative_examples_json}\n",
    "\n",
    "Respond with ONLY a valid JSON array where each element has \"id\", \"label\" keys and a confidence indicator where \n",
    "0 is not confident in the chosen label and 1 is confident in the chosen label.\n",
    "Example: [{{\"id\": 0, \"label\": \"Argumentative\", \"confidence\": 1}}, {{\"id\": 1, \"label\": \"Expressive\", \"confidence\": 0}}]\n",
    "\n",
    "Do not include any text outside the JSON array. No explanations, no markdown.\"\"\"\n",
    "\n",
    "VALID_LABELS = {\"Argumentative\", \"Informational\", \"Opinion\", \"Expressive\", \"Neutral\"}\n",
    "\n",
    "\n",
    "def format_batch(comments):\n",
    "    lines = []\n",
    "    for idx, comment in comments:\n",
    "        truncated = comment[:1500] if len(comment) > 1500 else comment\n",
    "        lines.append(f\"[{idx}] {truncated}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "\n",
    "def parse_response(response_text, expected_ids):\n",
    "    text = response_text.strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.split(\"\\n\", 1)[1]\n",
    "        text = text.rsplit(\"```\", 1)[0]\n",
    "\n",
    "    try:\n",
    "        results = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            results = ast.literal_eval(text)\n",
    "        except (ValueError, SyntaxError):\n",
    "            match = re.search(r'\\[.*\\]', text, re.DOTALL)\n",
    "            if match:\n",
    "                try:\n",
    "                    results = json.loads(match.group())\n",
    "                except json.JSONDecodeError:\n",
    "                    return {}\n",
    "            else:\n",
    "                return {}\n",
    "\n",
    "    if results and isinstance(results[0], list):\n",
    "        results = results[0]\n",
    "\n",
    "    labels = {}\n",
    "    for item in results:\n",
    "        idx = item.get(\"id\")\n",
    "        label = item.get(\"label\", \"\").strip()\n",
    "        conf = item.get(\"confidence\", \"\")\n",
    "        if idx not in expected_ids:\n",
    "            continue\n",
    "        if label not in VALID_LABELS:\n",
    "            matched = [v for v in VALID_LABELS if v.lower() == label.lower()]\n",
    "            if matched:\n",
    "                label = matched[0]\n",
    "            else:\n",
    "                continue\n",
    "        labels[idx] = {\"label\": label, \"confidence\": conf}\n",
    "    return labels\n",
    "\n",
    "\n",
    "def save_results(df):\n",
    "    if os.path.exists(OUTPUT_CSV):\n",
    "        existing = pd.read_csv(OUTPUT_CSV)\n",
    "        combined = pd.concat([existing, df], ignore_index=True)\n",
    "    else:\n",
    "        combined = df\n",
    "    combined.to_csv(OUTPUT_CSV, index=False)\n",
    "    return combined\n",
    "\n",
    "\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23830 comments to label\n",
      "477 requests to submit\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. ', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m chunk = all_requests[chunk_start:chunk_start + MAX_REQUESTS_PER_JOB]\n\u001b[32m     42\u001b[39m chunk_num = chunk_start // MAX_REQUESTS_PER_JOB\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m batch_job = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdisplay_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabeling-chunk-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchunk_num\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m job_names.append(batch_job.name)\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: submitted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunk)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requests -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_job.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\google\\genai\\batches.py:1968\u001b[39m, in \u001b[36mBatches.create\u001b[39m\u001b[34m(self, model, src, config)\u001b[39m\n\u001b[32m   1966\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create(model=model, src=src, config=config)\n\u001b[32m   1967\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1968\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\google\\genai\\batches.py:1555\u001b[39m, in \u001b[36mBatches._create\u001b[39m\u001b[34m(self, model, src, config)\u001b[39m\n\u001b[32m   1552\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   1553\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1555\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1559\u001b[39m response_dict = {} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.body \u001b[38;5;28;01melse\u001b[39;00m json.loads(response.body)\n\u001b[32m   1561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1396\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1386\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1387\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1388\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1391\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1392\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1393\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1394\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1395\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1397\u001b[39m   response_body = (\n\u001b[32m   1398\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1399\u001b[39m   )\n\u001b[32m   1400\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1232\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1229\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:470\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:371\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    369\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:413\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    411\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:184\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:473\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    475\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1209\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1201\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1202\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1203\u001b[39m       method=http_request.method,\n\u001b[32m   1204\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1207\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1208\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1211\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1212\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:134\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    132\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tkbar\\ADS\\ADS_509\\ADS-509_LLM\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:159\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    146\u001b[39m \n\u001b[32m    147\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    161\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. ', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}]}}"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Build inline requests and submit batch jobs\n",
    "#         (100 requests per job due to tier limit)\n",
    "# ============================================================\n",
    "\n",
    "df = subset1.copy()\n",
    "\n",
    "# Build batches of comments\n",
    "unlabeled_mask = df[\"label\"].isna()\n",
    "unlabeled_indices = df[unlabeled_mask].index.tolist()\n",
    "print(f\"{len(unlabeled_indices)} comments to label\")\n",
    "\n",
    "batches = []\n",
    "for i in range(0, len(unlabeled_indices), BATCH_SIZE):\n",
    "    batch_indices = unlabeled_indices[i:i + BATCH_SIZE]\n",
    "    batch = [(idx, str(df.loc[idx, COMMENT_COLUMN])) for idx in batch_indices]\n",
    "    batches.append(batch)\n",
    "\n",
    "print(f\"{len(batches)} requests to submit\")\n",
    "\n",
    "# Build inline requests\n",
    "all_requests = []\n",
    "batch_mapping = {}\n",
    "for i, batch in enumerate(batches):\n",
    "    expected_ids = [idx for idx, _ in batch]\n",
    "    batch_mapping[str(i)] = expected_ids\n",
    "    all_requests.append({\n",
    "        'contents': [{\n",
    "            'parts': [{'text': format_batch(batch)}],\n",
    "            'role': 'user'\n",
    "        }],\n",
    "        'config': {\n",
    "            'system_instruction': {'parts': [{'text': SYSTEM_PROMPT}]},\n",
    "            'thinking_config': {'thinking_level': 'minimal'}\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Submit in groups of MAX_REQUESTS_PER_JOB\n",
    "job_names = []\n",
    "for chunk_start in range(0, len(all_requests), MAX_REQUESTS_PER_JOB):\n",
    "    chunk = all_requests[chunk_start:chunk_start + MAX_REQUESTS_PER_JOB]\n",
    "    chunk_num = chunk_start // MAX_REQUESTS_PER_JOB\n",
    "\n",
    "    batch_job = client.batches.create(\n",
    "        model=MODEL,\n",
    "        src=chunk,\n",
    "        config={'display_name': f'labeling-chunk-{chunk_num}'}\n",
    "    )\n",
    "    job_names.append(batch_job.name)\n",
    "    print(f\"  Chunk {chunk_num}: submitted {len(chunk)} requests -> {batch_job.name}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# Save job names and mapping for retrieval later\n",
    "with open(JOB_NAMES_FILE, \"w\") as f:\n",
    "    json.dump({\"job_names\": job_names, \"batch_mapping\": batch_mapping}, f)\n",
    "\n",
    "print(f\"\\n{len(job_names)} batch jobs submitted\")\n",
    "print(f\"Saved to {JOB_NAMES_FILE}\")\n",
    "print(\"You can close your computer now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches/keh46cnqeyjuktw5xu4gtr904g1qu7owo5b5: JOB_STATE_SUCCEEDED\n",
      "batches/y8aors0wnhldx115ohdt0s48gwin7dsfpfrq: JOB_STATE_SUCCEEDED\n",
      "batches/9uouipfoblrwb4muh28cdadfh490nre1qnhg: JOB_STATE_SUCCEEDED\n",
      "batches/prlvcnjl4y95r2yvpvs5lxbvuj7rcr87k7yg: JOB_STATE_SUCCEEDED\n",
      "batches/gzss7lkccrx40bpzul86sdiwjdwls4kuw21o: JOB_STATE_SUCCEEDED\n",
      "batches/8ocypzlq34ogy680e23wrg9amzc1alc29735: JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Check batch status (run when you come back)\n",
    "# ============================================================\n",
    "\n",
    "with open(JOB_NAMES_FILE, \"r\") as f:\n",
    "    saved = json.load(f)\n",
    "    job_names = saved[\"job_names\"]\n",
    "\n",
    "for name in job_names:\n",
    "    job = client.batches.get(name=name)\n",
    "    print(f\"{job.name}: {job.state.name}\")\n",
    "    time.sleep(2)  # Delay between status checks to avoid 429 rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2.5: Check for errors in completed jobs\n",
    "# ============================================================\n",
    "\n",
    "with open(JOB_NAMES_FILE, \"r\") as f:\n",
    "    saved = json.load(f)\n",
    "    job_names = saved[\"job_names\"]\n",
    "\n",
    "for name in job_names:\n",
    "    job = client.batches.get(name=name)\n",
    "\n",
    "    if job.state.name == 'JOB_STATE_FAILED':\n",
    "        print(f\"{name}: FAILED\")\n",
    "        if hasattr(job, 'error') and job.error:\n",
    "            print(f\"  Error: {job.error}\")\n",
    "        time.sleep(2)\n",
    "        continue\n",
    "\n",
    "    if job.state.name != 'JOB_STATE_SUCCEEDED':\n",
    "        print(f\"{name}: {job.state.name} (still running)\")\n",
    "        time.sleep(2)\n",
    "        continue\n",
    "\n",
    "    # Check individual request errors within succeeded jobs\n",
    "    error_count = 0\n",
    "    for i, inline_response in enumerate(job.dest.inlined_responses):\n",
    "        if inline_response.error:\n",
    "            error_count += 1\n",
    "            if error_count <= 5:\n",
    "                print(f\"  {name} request {i}: {inline_response.error}\")\n",
    "\n",
    "    if error_count > 5:\n",
    "        print(f\"  ... and {error_count - 5} more errors\")\n",
    "    elif error_count == 0:\n",
    "        print(f\"{name}: all requests succeeded\")\n",
    "\n",
    "    time.sleep(2)  # Delay between job retrievals to avoid 429 rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Request 413: response.text is None — saved for debug\n",
      "\n",
      "DONE — 29799 comments labeled, 1 requests failed\n",
      "Saved to: gemini_comments_labeled_p1.csv (77513 total rows)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "Expressive       10525\n",
      "Opinion           8626\n",
      "Argumentative     6273\n",
      "Neutral           2633\n",
      "Informational     1807\n",
      "\n",
      "1 problematic responses saved to 'debug_responses' variable\n",
      "Also saved to gemini_debug_responses.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Retrieve results and save\n",
    "#         (run once all jobs show JOB_STATE_SUCCEEDED)\n",
    "# ============================================================\n",
    "\n",
    "with open(JOB_NAMES_FILE, \"r\") as f:\n",
    "    saved = json.load(f)\n",
    "    job_names = saved[\"job_names\"]\n",
    "    batch_mapping = saved[\"batch_mapping\"]\n",
    "\n",
    "df = subset1.copy()\n",
    "total_labeled = 0\n",
    "failed = 0\n",
    "request_idx = 0\n",
    "debug_responses = []  # Save problematic responses for inspection\n",
    "\n",
    "for name in job_names:\n",
    "    job = client.batches.get(name=name)\n",
    "    time.sleep(2)  # Delay between job retrievals to avoid 429 rate limit\n",
    "\n",
    "    if job.state.name != 'JOB_STATE_SUCCEEDED':\n",
    "        print(f\"  Skipping {name} — state: {job.state.name}\")\n",
    "        chunk_size = min(MAX_REQUESTS_PER_JOB, len(batch_mapping) - request_idx)\n",
    "        request_idx += chunk_size\n",
    "        continue\n",
    "\n",
    "    for inline_response in job.dest.inlined_responses:\n",
    "        expected_ids = batch_mapping[str(request_idx)]\n",
    "\n",
    "        if inline_response.response:\n",
    "            response_text = inline_response.response.text\n",
    "\n",
    "            # Handle None or empty text (e.g. thinking consumed all tokens)\n",
    "            if not response_text:\n",
    "                failed += 1\n",
    "                debug_responses.append({\n",
    "                    \"request_idx\": request_idx,\n",
    "                    \"job_name\": name,\n",
    "                    \"issue\": \"response.text is None/empty\",\n",
    "                    \"response_obj\": str(inline_response.response)\n",
    "                })\n",
    "                print(f\"  Request {request_idx}: response.text is None — saved for debug\")\n",
    "                request_idx += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                labels = parse_response(response_text, expected_ids)\n",
    "            except (AttributeError, TypeError) as e:\n",
    "                failed += 1\n",
    "                debug_responses.append({\n",
    "                    \"request_idx\": request_idx,\n",
    "                    \"job_name\": name,\n",
    "                    \"issue\": str(e),\n",
    "                    \"response_text\": response_text[:500] if response_text else None,\n",
    "                    \"response_obj\": str(inline_response.response)\n",
    "                })\n",
    "                print(f\"  Request {request_idx}: parse error ({e}) — saved for debug\")\n",
    "                request_idx += 1\n",
    "                continue\n",
    "\n",
    "            for idx, value in labels.items():\n",
    "                df.loc[idx, \"label\"] = value[\"label\"]\n",
    "                df.loc[idx, \"confidence\"] = value[\"confidence\"]\n",
    "\n",
    "            total_labeled += len(labels)\n",
    "        else:\n",
    "            failed += 1\n",
    "            print(f\"  Request {request_idx} failed: {inline_response.error}\")\n",
    "\n",
    "        request_idx += 1\n",
    "\n",
    "combined = save_results(df)\n",
    "\n",
    "print(f\"\\nDONE — {total_labeled} comments labeled, {failed} requests failed\")\n",
    "print(f\"Saved to: {OUTPUT_CSV} ({len(combined)} total rows)\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df[\"label\"].value_counts().to_string())\n",
    "\n",
    "if debug_responses:\n",
    "    print(f\"\\n{len(debug_responses)} problematic responses saved to 'debug_responses' variable\")\n",
    "    with open(\"gemini_debug_responses.json\", \"w\") as f:\n",
    "        json.dump(debug_responses, f, indent=2)\n",
    "    print(\"Also saved to gemini_debug_responses.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gemini_comments_labeled_p1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS-509_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
