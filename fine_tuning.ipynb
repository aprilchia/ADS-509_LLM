{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f26c9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "os.environ[\"TENSORBOARD_LOGGING_DIR\"] = \"./logs\"\n",
    "\n",
    "MODEL_ID = 'vinai/bertweet-large'\n",
    "\n",
    "# check for gpu\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27aeab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use your hugging face token to log in\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a4628fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1acbae4d47748f8a2cf25a628db78f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/895 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030aab7466d545e98dceae0f8ee03639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63341fa5481a4bc1842cc3d85b9c2928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/819k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf4ad725d7642c9aec7603c6f0cd658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/valid-00000-of-00001.parquet:   0%|          | 0.00/794k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212a2933d9c040c98a322b93bb9187de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/23949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ad1ff559bc4420a7ddb664b20a54bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5133 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ef724cd9364842a3b32aa2fcec1ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/5132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"ADS509/experiment_labels_full_match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up label mapping objects to store with data and model\n",
    "label2id = {}\n",
    "id2label = {}\n",
    "\n",
    "for i, label in enumerate(dataset['train'].features['label'].names):\n",
    "\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7062c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Function to tokenize data with\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        truncation=True, \n",
    "        max_length=512 \n",
    "    )\n",
    "# Data collator handles padding dynamically, set padding and max_length if you want to control it explicitly and drop the collator\n",
    "\n",
    "# Tokenize Data\n",
    "train_data = dataset['train'].map(tokenize_function, batched=True)\n",
    "test_data = dataset['test'].map(tokenize_function, batched=True)\n",
    "valid_data = dataset['valid'].map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert lists to tensors\n",
    "train_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "test_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "valid_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "    \n",
    "# Verify batch\n",
    "test_loader = DataLoader(train_data, batch_size=4)\n",
    "batch = next(iter(test_loader))\n",
    "print(f\"Batch keys: {batch.keys()}\")\n",
    "print(f\"Input IDs shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Labels shape: {batch['label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbede08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a repo name to save the trained model to\n",
    "# model_repo = \"experiment_labels_bert_base\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=5,\n",
    "    device_map='cuda',\n",
    "    dtype='auto',\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "# Metric function for evaluation in Trainer\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'f1_macro': f1_score(labels, predictions, average='macro'),\n",
    "        'f1_weighted': f1_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "\n",
    "# Data collator to handle padding dynamically per batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./bert-comment', # Saves it locally\n",
    "    #push_to_hub=True,\n",
    "    #hub_model_id=f\"ADS509/{model_repo}\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,\n",
    "    \n",
    "    # Evaluation & saving\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_macro',\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=100,\n",
    "    report_to='tensorboard',\n",
    "    \n",
    "    # Other\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model to hugging face model repo\n",
    "trainer.save_model(training_args.output_dir)\n",
    "trainer.push_to_hub(commit_message = \"BERTweet-large with correct labels on full match data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96861f00",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf010d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9pvk2mukb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Trainer's built-in hyperparameter_search with Optuna\n",
    "import optuna\n",
    "import transformers\n",
    "import logging\n",
    "\n",
    "def model_init():\n",
    "    # Temporarily suppress model load reports\n",
    "    transformers.logging.set_verbosity_error()\n",
    "    logging.getLogger(\"accelerate.utils.modeling\").setLevel(logging.ERROR)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        num_labels=5,\n",
    "        device_map='cuda',\n",
    "        dtype='auto',\n",
    "    )\n",
    "    transformers.logging.set_verbosity_warning()\n",
    "    logging.getLogger(\"accelerate.utils.modeling\").setLevel(logging.WARNING)\n",
    "    return model\n",
    "\n",
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"num_train_epochs\": trial.suggest_int(\"epochs\", 2, 3),\n",
    "        \"learning_rate\": trial.suggest_float(\"lr\", 1e-5, 1e-4, log=True),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup\", 100, 300, step=50),\n",
    "        \"weight_decay\": trial.suggest_float(\"decay\", 0, 0.2, step=0.05),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32, 64]),\n",
    "        \"optim\": trial.suggest_categorical(\"optimizer\", [\"adamw_torch\", \"adamw_torch_fused\", \"adafactor\"]),\n",
    "    }\n",
    "\n",
    "search_args = TrainingArguments(\n",
    "    output_dir='./hp-search',\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='no',\n",
    "    metric_for_best_model='f1_macro',\n",
    "    report_to='none',\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "hp_trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=search_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "best_run = hp_trainer.hyperparameter_search(\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1_macro\"],\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    n_trials=10,\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=2, n_warmup_steps=1),\n",
    ")\n",
    "\n",
    "print(\"Best run:\")\n",
    "print(f\"  F1 Macro: {best_run.objective:.4f}\")\n",
    "print(f\"  Params: {best_run.hyperparameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9hyi1n3jbnu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with best hyperparameters from hyperparameter_search and push to Hub\n",
    "repo_id = \"best_hp_tuning_v1\"\n",
    "\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=5,\n",
    "    device_map='cuda',\n",
    "    dtype='auto',\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")\n",
    "\n",
    "best_hp = best_run.hyperparameters\n",
    "best_args = TrainingArguments(\n",
    "    output_dir=f'./best-{repo_id}',\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=f\"ADS509/{repo_id}\",\n",
    "    optim=best_hp['optimizer'],\n",
    "    num_train_epochs=best_hp['epochs'],\n",
    "    per_device_train_batch_size=best_hp['batch_size'],\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=best_hp['lr'],\n",
    "    weight_decay=best_hp['decay'],\n",
    "    warmup_steps=best_hp['warmup'],\n",
    "\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_macro',\n",
    "\n",
    "    logging_steps=100,\n",
    "    report_to='tensorboard',\n",
    "\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "best_trainer = Trainer(\n",
    "    model=best_model,\n",
    "    args=best_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "best_trainer.train()\n",
    "eval_results = best_trainer.evaluate()\n",
    "print(eval_results)\n",
    "\n",
    "best_trainer.save_model(best_args.output_dir)\n",
    "best_trainer.push_to_hub(commit_message=f\"Best model from HP search (f1_macro={best_run.objective:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
