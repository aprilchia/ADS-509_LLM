{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4624d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c4aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments = pd.read_csv(\"data/full_comments.csv\")\n",
    "examples = full_comments.loc[full_comments['true_label'].notna(), [\"comment_text\", \"true_label\"]].head(10)\n",
    "negative_examples = pd.read_excel(\"negative_examples.xlsx\", names=['comment_text', 'original_label', 'corrected_label'])\n",
    "\n",
    "examples = examples.rename(columns={\"comment_text\": \"comment\", \"true_label\": \"label\"})\n",
    "\n",
    "examples_json = json.dumps(examples.to_dict(orient=\"records\"), indent=2)\n",
    "\n",
    "negative_examples_json = json.dumps(negative_examples.to_dict(orient=\"records\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c0f0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = full_comments.sample(30000, random_state=10)\n",
    "subset['label'] = subset['true_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e596b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_CSV = \"data/full_comments.csv\"           # Path to your CSV file\n",
    "COMMENT_COLUMN = \"comment_text\"           # Column name containing the comment text\n",
    "OUTPUT_CSV = \"comments_labeled.csv\"  # Where to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b3ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get('ANTHROPIC_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comment Function Labeling Script\n",
    "=================================\n",
    "Uses the Anthropic API to classify comments into one of five categories:\n",
    "Argumentative, Informational, Opinion, Expressive, Neutral\n",
    "\n",
    "Usage:\n",
    "    1. Set your API key: export ANTHROPIC_API_KEY=\"your-key-here\"\n",
    "    2. Update INPUT_CSV and COMMENT_COLUMN below to match your data\n",
    "    3. Run: python label_comments.py\n",
    "\n",
    "Requirements:\n",
    "    pip install anthropic pandas\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION — Update these to match your data\n",
    "# ============================================================\n",
    "\n",
    "MODEL = \"claude-haiku-4-5-20251001\"  # Fast and cheap, great for classification\n",
    "BATCH_SIZE = 50                      # Comments per API call\n",
    "SAVE_EVERY = 2                       # Save progress every N batches\n",
    "\n",
    "# ============================================================\n",
    "# LABEL DEFINITIONS (from your labels.md)\n",
    "# ============================================================\n",
    "SYSTEM_PROMPT = f\"\"\"You are a comment classifier. You will be given a batch of comments, each with an ID number. \n",
    "Classify each comment into exactly ONE of these five categories:\n",
    "\n",
    "**Argumentative**\n",
    "- Makes specific claims, predictions, or assertions supported by reasoning\n",
    "- Uses evidence, anecdotes, or scenarios to build a case\n",
    "- The key distinction from Opinion: there's an attempt to *persuade* or *explain why*, not just state a position\n",
    "\n",
    "**Informational**\n",
    "- Shares facts, data, links, or context relevant to the discussion\n",
    "- Low emotional affect — the comment is trying to *inform*, not convince or react\n",
    "- Includes answering another commenter's question with factual content\n",
    "- The key distinction from Argumentative: presenting information without advocating for a position\n",
    "\n",
    "**Opinion**\n",
    "- States a value judgment, stance, or take without substantial reasoning\n",
    "- \"This is good/bad/wrong/overrated\" — the comment *asserts* but doesn't *argue*\n",
    "- The key distinction from Argumentative: no real attempt to persuade or support the claim\n",
    "- The key distinction from Expressive: the comment is making a point, not just reacting\n",
    "\n",
    "**Expressive**\n",
    "- Emotional reactions, sarcasm, jokes, venting, exclamations\n",
    "- The comment is primarily *expressing feeling* rather than making a point\n",
    "- Includes performative agreement/disagreement (\"THIS,\" \"lol exactly,\" \"what a joke\")\n",
    "- The key distinction from Opinion: no identifiable stance being taken, just affect\n",
    "\n",
    "**Neutral**\n",
    "- Clarifying or rhetorical questions, meta-commentary, off-topic remarks\n",
    "- Comments that don't clearly fit the other four categories\n",
    "- Includes simple factual questions directed at other commenters\n",
    "\n",
    "**Correctly labeled examples** — these demonstrate the correct label for each comment:\n",
    "{examples_json}\n",
    "\n",
    "**Incorrectly labeled examples** — these were originally mislabeled. The \"original_label\" is the wrong label that was assigned, and the \"corrected_label\" is what the label should have been. Use these to understand common mistakes to avoid:\n",
    "{negative_examples_json}\n",
    "\n",
    "Respond with ONLY a valid JSON array where each element has \"id\", \"label\" keys and a confidence indicator where \n",
    "0 is not confident in the chosen label and 1 is confident in the chosen label.\n",
    "Example: [{{\"id\": 0, \"label\": \"Argumentative\", \"confidence\": 1}}, {{\"id\": 1, \"label\": \"Expressive\", \"confidence\": 0}}]\n",
    "\n",
    "Do not include any text outside the JSON array. No explanations, no markdown.\"\"\"\n",
    "\n",
    "\n",
    "VALID_LABELS = {\"Argumentative\", \"Informational\", \"Opinion\", \"Expressive\", \"Neutral\"}\n",
    "\n",
    "\n",
    "def format_batch(comments: list[tuple[int, str]]) -> str:\n",
    "    \"\"\"Format a batch of (id, comment) tuples into the user message.\"\"\"\n",
    "    lines = []\n",
    "    for idx, comment in comments:\n",
    "        # Truncate very long comments to avoid token waste\n",
    "        truncated = comment[:1500] if len(comment) > 1500 else comment\n",
    "        lines.append(f\"[{idx}] {truncated}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "\n",
    "def save_results(df):\n",
    "    \"\"\"Concat new results with existing OUTPUT_CSV if it exists, then save.\"\"\"\n",
    "    if os.path.exists(OUTPUT_CSV):\n",
    "        existing = pd.read_csv(OUTPUT_CSV)\n",
    "        combined = pd.concat([existing, df], ignore_index=True)\n",
    "    else:\n",
    "        combined = df\n",
    "    combined.to_csv(OUTPUT_CSV, index=False)\n",
    "    return combined\n",
    "\n",
    "\n",
    "def parse_response(response_text: str, expected_ids: list[int]) -> dict[int, str]:\n",
    "    \"\"\"Parse the API response JSON into a dict of {id: label}.\"\"\"\n",
    "    text = response_text.strip()\n",
    "\n",
    "    # Strip markdown code fences\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.split(\"\\n\", 1)[1]\n",
    "        text = text.rsplit(\"```\", 1)[0]\n",
    "\n",
    "    # Try standard JSON first\n",
    "    try:\n",
    "        results = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Model may return Python-style output (single quotes) instead of JSON\n",
    "        try:\n",
    "            results = ast.literal_eval(text)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # Last resort: find the first JSON array in the text\n",
    "            match = re.search(r'\\[.*\\]', text, re.DOTALL)\n",
    "            if match:\n",
    "                try:\n",
    "                    results = json.loads(match.group())\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"  WARNING: Failed to parse response\")\n",
    "                    return {}\n",
    "            else:\n",
    "                print(f\"  WARNING: No JSON array found in response\")\n",
    "                return {}\n",
    "\n",
    "    # Unwrap nested list if model double-wrapped the array\n",
    "    if results and isinstance(results[0], list):\n",
    "        results = results[0]\n",
    "\n",
    "    labels = {}\n",
    "    for item in results:\n",
    "        idx = item.get(\"id\")\n",
    "        label = item.get(\"label\", \"\").strip()\n",
    "        conf = item.get('confidence', \"\")\n",
    "        \n",
    "        # Validate\n",
    "        if idx not in expected_ids:\n",
    "            print(f\"  WARNING: Unexpected ID {idx} in response\")\n",
    "            continue\n",
    "        if label not in VALID_LABELS:\n",
    "            # Try case-insensitive match\n",
    "            matched = [v for v in VALID_LABELS if v.lower() == label.lower()]\n",
    "            if matched:\n",
    "                label = matched[0]\n",
    "            else:\n",
    "                print(f\"  WARNING: Invalid label '{label}' for ID {idx}\")\n",
    "                continue\n",
    "        \n",
    "        labels[idx] = {\"label\": label, \"confidence\": conf}\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def label_batch(client: Anthropic, comments: list[tuple[int, str]], max_retries: int = 3) -> dict[int, str]:\n",
    "    \"\"\"Send a batch to the API and return labels. Retries on failure.\"\"\"\n",
    "    user_message = format_batch(comments)\n",
    "    expected_ids = [idx for idx, _ in comments]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.messages.create(\n",
    "                model=MODEL,\n",
    "                max_tokens=1024,\n",
    "                system=SYSTEM_PROMPT,\n",
    "                messages=[{\"role\": \"user\", \"content\": user_message}]\n",
    "            )\n",
    "            \n",
    "            response_text = response.content[0].text\n",
    "            labels = parse_response(response_text, expected_ids)\n",
    "            \n",
    "            # Check if we got all expected labels\n",
    "            missing = set(expected_ids) - set(labels.keys())\n",
    "            if missing:\n",
    "                print(f\"  WARNING: Missing labels for IDs {missing}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"  Retrying... (attempt {attempt + 2}/{max_retries})\")\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "            \n",
    "            return labels\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait = 2 ** attempt  # Exponential backoff\n",
    "                print(f\"  Retrying in {wait}s... (attempt {attempt + 2}/{max_retries})\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                print(f\"  Failed after {max_retries} attempts\")\n",
    "                return {}\n",
    "    \n",
    "    return {}\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = subset.copy()\n",
    "    print(f\"  {len(df)} rows loaded\")\n",
    "    \n",
    "    if COMMENT_COLUMN not in df.columns:\n",
    "        print(f\"ERROR: Column '{COMMENT_COLUMN}' not found. Available columns: {list(df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    # Skip rows that already have labels (for resuming interrupted runs)\n",
    "    if \"label\" not in df.columns:\n",
    "        df[\"label\"] = None\n",
    "    \n",
    "    unlabeled_mask = df[\"label\"].isna()\n",
    "    unlabeled_indices = df[unlabeled_mask].index.tolist()\n",
    "    print(f\"  {len(unlabeled_indices)} comments to label ({len(df) - len(unlabeled_indices)} already labeled)\")\n",
    "    \n",
    "    if not unlabeled_indices:\n",
    "        print(\"All comments already labeled!\")\n",
    "        return\n",
    "    \n",
    "    # Create batches\n",
    "    batches = []\n",
    "    for i in range(0, len(unlabeled_indices), BATCH_SIZE):\n",
    "        batch_indices = unlabeled_indices[i:i + BATCH_SIZE]\n",
    "        batch = [(idx, str(df.loc[idx, COMMENT_COLUMN])) for idx in batch_indices]\n",
    "        batches.append(batch)\n",
    "    \n",
    "    print(f\"  {len(batches)} batches of ~{BATCH_SIZE} comments each\\n\")\n",
    "    \n",
    "    # Process\n",
    "    client = Anthropic(api_key=api_key)\n",
    "    total_labeled = 0\n",
    "    \n",
    "    for batch_num, batch in enumerate(batches, 1):\n",
    "        print(f\"Batch {batch_num}/{len(batches)} ({len(batch)} comments)...\", end=\" \")\n",
    "        \n",
    "        labels = label_batch(client, batch)\n",
    "        \n",
    "        # Write labels to dataframe\n",
    "        for idx, value in labels.items():\n",
    "            df.loc[idx, \"label\"] = value['label']\n",
    "            df.loc[idx, \"confidence\"] = value['confidence']\n",
    "        \n",
    "        total_labeled += len(labels)\n",
    "        print(f\"got {len(labels)} labels (total: {total_labeled}/{len(unlabeled_indices)})\")\n",
    "        \n",
    "        # Periodic save — concat with existing file\n",
    "        if batch_num % SAVE_EVERY == 0:\n",
    "            combined = save_results(df)\n",
    "            print(f\"  >> Progress saved to {OUTPUT_CSV} ({len(combined)} total rows)\")\n",
    "        \n",
    "        # Small delay to stay well within rate limits\n",
    "        if batch_num < len(batches):\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    # Final save — concat with existing file\n",
    "    combined = save_results(df)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"DONE — {total_labeled} comments labeled\")\n",
    "    print(f\"Saved to: {OUTPUT_CSV} ({len(combined)} total rows)\")\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(df[\"label\"].value_counts().to_string())\n",
    "    \n",
    "    # Check for any still-unlabeled\n",
    "    still_missing = df[\"label\"].isna().sum()\n",
    "    if still_missing:\n",
    "        print(f\"\\nWARNING: {still_missing} comments still unlabeled (API failures)\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7790b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 rows loaded\n",
      "  101 comments to label (0 already labeled)\n",
      "  4 batches of ~30 comments each\n",
      "\n",
      "Batch 1/4 (30 comments)... got 30 labels (total: 30/101)\n",
      "Batch 2/4 (30 comments)... got 30 labels (total: 60/101)\n",
      "Batch 3/4 (30 comments)... got 30 labels (total: 90/101)\n",
      "Batch 4/4 (11 comments)... got 11 labels (total: 101/101)\n",
      "\n",
      "==================================================\n",
      "DONE — 101 comments labeled\n",
      "Saved to: comments_labeled.csv (5103 total rows)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "Expressive       28\n",
      "Opinion          26\n",
      "Neutral          17\n",
      "Argumentative    16\n",
      "Informational    14\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5103, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv(\"comments_labeled.csv\")\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "776c571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_labeled = pd.concat([new_df, new_df1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS-509_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
