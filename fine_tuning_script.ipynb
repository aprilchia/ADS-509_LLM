{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f26c9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "os.environ[\"TENSORBOARD_LOGGING_DIR\"] = \"./logs\"\n",
    "\n",
    "MODEL_ID = 'bert-base-uncased'\n",
    "\n",
    "# check for gpu\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aeab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08675992879b4aa19ed38cc454f7952e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use your hugging face token to log in\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4628fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d43cf48d3a40849cd7b8ba41c7cacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680a4ba81af845c68c225a0401ee8dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "experiment-labels/train-00000-of-00001.p(…):   0%|          | 0.00/2.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1d8fe0984345b29f2f8a49949463a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "experiment-labels/valid-00000-of-00001.p(…):   0%|          | 0.00/572k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d0f05fb6f448e0a19b93781dcf1c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "experiment-labels/test-00000-of-00001.pa(…):   0%|          | 0.00/545k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3292f4d263a402e9d33498057cd1db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e4c6c25fc641d19c8925bb886b8d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea9a49e3ec44bf5a97055bf969248bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset you're using, don't forget to specify the data directory\n",
    "dataset = load_dataset('ADS509/final_project_data', data_dir=\"experiment-labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7062c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f39cf59d948436ca792ef7c304c33a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f7715401e84627961dad2f5b8ce927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a78e7ed6f8b447f8d5106e7616545bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c028d95a44f4069915fe40f5ec43c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0205ad6b194967a9b7f495fca8d130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20089 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6503becbdf4743ae6c64f865263574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbe3ffb18ea41dfb137cec4a8eff304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['label', 'input_ids', 'attention_mask'])\n",
      "Input IDs shape: torch.Size([4, 512])\n",
      "Labels shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Function to tokenize data with\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        truncation=True, \n",
    "        padding='max_length',\n",
    "       # max_length=128 # Can't be greater than model max length\n",
    "    )\n",
    "# Data collator handles padding dynamically, set padding and max_length if you want to control it explicitly and drop the collator\n",
    "\n",
    "# Tokenize Data\n",
    "train_data = dataset['train'].map(tokenize_function, batched=True)\n",
    "test_data = dataset['test'].map(tokenize_function, batched=True)\n",
    "valid_data = dataset['validation'].map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert lists to tensors\n",
    "train_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "test_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "valid_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "\n",
    "    \n",
    "# Verify batch\n",
    "test_loader = DataLoader(train_data, batch_size=4)\n",
    "batch = next(iter(test_loader))\n",
    "print(f\"Batch keys: {batch.keys()}\")\n",
    "print(f\"Input IDs shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Labels shape: {batch['label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbede08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a repo name to save the trained model to\n",
    "model_repo = \"experiment_labels_4epochs\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=5, # adjust this based on number of labels you're training on\n",
    "    device_map='cuda',\n",
    "    dtype='auto',\n",
    "    #label2id={}, # set these two args to attach the metadata to the model.config\n",
    "    #id2label={}\n",
    ")\n",
    "\n",
    "# Metric function for evaluation in Trainer\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'f1_macro': f1_score(labels, predictions, average='macro'),\n",
    "        'f1_weighted': f1_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "\n",
    "# Data collator to handle padding dynamically per batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./bert-comment-classifier', # Saves it locally\n",
    "    #push_to_hub=True,\n",
    "    #hub_model_id=f\"ADS509/{model_repo}\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,  # or warmup_ratio=%\n",
    "    \n",
    "    # Evaluation & saving\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_macro',\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=100,\n",
    "    report_to='tensorboard',\n",
    "    \n",
    "    # Other\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision if GPU available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train!\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model to hugging face model repo\n",
    "trainer.save_model(training_args.output_dir)\n",
    "trainer.push_to_hub(commit_message = \"Bert based trained on original dataset with 4 epochs instead of 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96861f00",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcf010d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.4)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (26.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
      "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.10.1 optuna-4.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "i9pvk2mukb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf33f0d8ae74f56952eba13034b4799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:14:59,506] A new study created in memory with name: no-name-48ce9dfd-1a1f-48bd-b8b9-136940eaa389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6cf869a2ad4d20981533aa969a9da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2512' max='2512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2512/2512 05:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.750115</td>\n",
       "      <td>0.648883</td>\n",
       "      <td>0.755865</td>\n",
       "      <td>0.733465</td>\n",
       "      <td>0.755616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.568294</td>\n",
       "      <td>0.634139</td>\n",
       "      <td>0.768177</td>\n",
       "      <td>0.747090</td>\n",
       "      <td>0.767789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:20:27,839] Trial 0 finished with value: 0.7470902819414769 and parameters: {'epochs': 2, 'lr': 1.051160407564676e-05, 'warmup': 250, 'decay': 0.0, 'batch_size': 16, 'optimizer': 'adafactor'}. Best is trial 0 with value: 0.7470902819414769.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279d7782820a474eb128ae1e4046c091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3768' max='3768' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3768/3768 08:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.758985</td>\n",
       "      <td>0.644505</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.715971</td>\n",
       "      <td>0.742534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.421190</td>\n",
       "      <td>0.712686</td>\n",
       "      <td>0.757259</td>\n",
       "      <td>0.729953</td>\n",
       "      <td>0.756097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144698</td>\n",
       "      <td>1.106418</td>\n",
       "      <td>0.752846</td>\n",
       "      <td>0.730903</td>\n",
       "      <td>0.752814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:28:38,607] Trial 1 finished with value: 0.7309025520913577 and parameters: {'epochs': 3, 'lr': 6.093358472258432e-05, 'warmup': 300, 'decay': 0.05, 'batch_size': 16, 'optimizer': 'adafactor'}. Best is trial 0 with value: 0.7470902819414769.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4a3d466bf5451a8bbc338d3f6e7f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3768' max='3768' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3768/3768 05:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.642407</td>\n",
       "      <td>0.753078</td>\n",
       "      <td>0.731300</td>\n",
       "      <td>0.754156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.509342</td>\n",
       "      <td>0.620961</td>\n",
       "      <td>0.768873</td>\n",
       "      <td>0.744829</td>\n",
       "      <td>0.768240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.351735</td>\n",
       "      <td>0.667766</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.744628</td>\n",
       "      <td>0.766812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:33:46,751] Trial 2 finished with value: 0.7446279899033907 and parameters: {'epochs': 3, 'lr': 1.341775767508709e-05, 'warmup': 100, 'decay': 0.05, 'batch_size': 16, 'optimizer': 'adamw_torch'}. Best is trial 0 with value: 0.7470902819414769.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff38943489f4a9b9a13bfa29485b521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1256' max='2512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1256/2512 01:42 < 01:42, 12.23 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.713851</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.754007</td>\n",
       "      <td>0.729340</td>\n",
       "      <td>0.755236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:35:30,413] Trial 3 pruned. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22ea99e2a8e499992876b956dcd6519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='942' max='942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [942/942 03:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688948</td>\n",
       "      <td>0.740534</td>\n",
       "      <td>0.704881</td>\n",
       "      <td>0.739108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.902736</td>\n",
       "      <td>0.628435</td>\n",
       "      <td>0.767712</td>\n",
       "      <td>0.742855</td>\n",
       "      <td>0.766165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.902736</td>\n",
       "      <td>0.631698</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>0.748856</td>\n",
       "      <td>0.770700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:39:28,431] Trial 4 finished with value: 0.748856283879789 and parameters: {'epochs': 3, 'lr': 1.5814997059293325e-05, 'warmup': 250, 'decay': 0.2, 'batch_size': 64, 'optimizer': 'adamw_torch_fused'}. Best is trial 4 with value: 0.748856283879789.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7261d3ad5f644246ac5824443132a1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='628' max='942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [628/942 03:11 < 01:35, 3.28 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682212</td>\n",
       "      <td>0.738444</td>\n",
       "      <td>0.712092</td>\n",
       "      <td>0.738847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.884336</td>\n",
       "      <td>0.626238</td>\n",
       "      <td>0.767247</td>\n",
       "      <td>0.737637</td>\n",
       "      <td>0.765989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:42:40,827] Trial 5 pruned. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc1d63450c04209a8171ef37d7bfa47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='628' max='1884' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 628/1884 01:59 < 03:59, 5.25 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.932527</td>\n",
       "      <td>0.665984</td>\n",
       "      <td>0.737515</td>\n",
       "      <td>0.714094</td>\n",
       "      <td>0.740223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:44:41,443] Trial 6 pruned. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f616462c644482d8d3893d97b81d3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='628' max='1884' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 628/1884 01:28 < 02:57, 7.08 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.916218</td>\n",
       "      <td>0.652797</td>\n",
       "      <td>0.741231</td>\n",
       "      <td>0.717268</td>\n",
       "      <td>0.744275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:46:11,068] Trial 7 pruned. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f5bd9ad4a241b5aaa823ac5c2cf09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='628' max='628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [628/628 02:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.657697</td>\n",
       "      <td>0.745412</td>\n",
       "      <td>0.716780</td>\n",
       "      <td>0.743362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.769868</td>\n",
       "      <td>0.612395</td>\n",
       "      <td>0.768641</td>\n",
       "      <td>0.747426</td>\n",
       "      <td>0.768128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:48:52,577] Trial 8 finished with value: 0.7474260411977679 and parameters: {'epochs': 2, 'lr': 5.97626461849483e-05, 'warmup': 250, 'decay': 0.0, 'batch_size': 64, 'optimizer': 'adamw_torch'}. Best is trial 4 with value: 0.748856283879789.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f015fcea494148459e821b234cf86580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='628' max='1256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 628/1256 01:28 < 01:28, 7.08 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.835400</td>\n",
       "      <td>0.641677</td>\n",
       "      <td>0.745180</td>\n",
       "      <td>0.718317</td>\n",
       "      <td>0.747261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 20:50:22,185] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run:\n",
      "  F1 Macro: 0.7489\n",
      "  Params: {'epochs': 3, 'lr': 1.5814997059293325e-05, 'warmup': 250, 'decay': 0.2, 'batch_size': 64, 'optimizer': 'adamw_torch_fused'}\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Trainer's built-in hyperparameter_search with Optuna\n",
    "import optuna\n",
    "import transformers\n",
    "import logging\n",
    "\n",
    "def model_init():\n",
    "    # Temporarily suppress model load reports\n",
    "    transformers.logging.set_verbosity_error()\n",
    "    logging.getLogger(\"accelerate.utils.modeling\").setLevel(logging.ERROR)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        num_labels=5,\n",
    "        device_map='cuda',\n",
    "        dtype='auto',\n",
    "    )\n",
    "    transformers.logging.set_verbosity_warning()\n",
    "    logging.getLogger(\"accelerate.utils.modeling\").setLevel(logging.WARNING)\n",
    "    return model\n",
    "\n",
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"num_train_epochs\": trial.suggest_int(\"epochs\", 2, 3),\n",
    "        \"learning_rate\": trial.suggest_float(\"lr\", 1e-5, 1e-4, log=True),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup\", 100, 300, step=50),\n",
    "        \"weight_decay\": trial.suggest_float(\"decay\", 0, 0.2, step=0.05),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32, 64]),\n",
    "        \"optim\": trial.suggest_categorical(\"optimizer\", [\"adamw_torch\", \"adamw_torch_fused\", \"adafactor\"]),\n",
    "    }\n",
    "\n",
    "search_args = TrainingArguments(\n",
    "    output_dir='./hp-search',\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='no',\n",
    "    metric_for_best_model='f1_macro',\n",
    "    report_to='none',\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "hp_trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=search_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "best_run = hp_trainer.hyperparameter_search(\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1_macro\"],\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    n_trials=10,\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=2, n_warmup_steps=1),\n",
    ")\n",
    "\n",
    "print(\"Best run:\")\n",
    "print(f\"  F1 Macro: {best_run.objective:.4f}\")\n",
    "print(f\"  Params: {best_run.hyperparameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9hyi1n3jbnu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffb1569b92b4140a6529420d836c504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='942' max='942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [942/942 04:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.756105</td>\n",
       "      <td>0.677377</td>\n",
       "      <td>0.743089</td>\n",
       "      <td>0.705627</td>\n",
       "      <td>0.740832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.590700</td>\n",
       "      <td>0.615951</td>\n",
       "      <td>0.763995</td>\n",
       "      <td>0.739051</td>\n",
       "      <td>0.762198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.477321</td>\n",
       "      <td>0.621482</td>\n",
       "      <td>0.765854</td>\n",
       "      <td>0.742929</td>\n",
       "      <td>0.765828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93950fb8b9d347428e8dbaa68fede680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b9bc5aabfc4f3db20a03c0919eed60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244714dd1e044f49a00a6045fd17ddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['bert.embeddings.LayerNorm.beta', 'bert.embeddings.LayerNorm.gamma', 'bert.encoder.layer.0.attention.output.LayerNorm.beta', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma', 'bert.encoder.layer.0.output.LayerNorm.beta', 'bert.encoder.layer.0.output.LayerNorm.gamma', 'bert.encoder.layer.1.attention.output.LayerNorm.beta', 'bert.encoder.layer.1.attention.output.LayerNorm.gamma', 'bert.encoder.layer.1.output.LayerNorm.beta', 'bert.encoder.layer.1.output.LayerNorm.gamma', 'bert.encoder.layer.2.attention.output.LayerNorm.beta', 'bert.encoder.layer.2.attention.output.LayerNorm.gamma', 'bert.encoder.layer.2.output.LayerNorm.beta', 'bert.encoder.layer.2.output.LayerNorm.gamma', 'bert.encoder.layer.3.attention.output.LayerNorm.beta', 'bert.encoder.layer.3.attention.output.LayerNorm.gamma', 'bert.encoder.layer.3.output.LayerNorm.beta', 'bert.encoder.layer.3.output.LayerNorm.gamma', 'bert.encoder.layer.4.attention.output.LayerNorm.beta', 'bert.encoder.layer.4.attention.output.LayerNorm.gamma', 'bert.encoder.layer.4.output.LayerNorm.beta', 'bert.encoder.layer.4.output.LayerNorm.gamma', 'bert.encoder.layer.5.attention.output.LayerNorm.beta', 'bert.encoder.layer.5.attention.output.LayerNorm.gamma', 'bert.encoder.layer.5.output.LayerNorm.beta', 'bert.encoder.layer.5.output.LayerNorm.gamma', 'bert.encoder.layer.6.attention.output.LayerNorm.beta', 'bert.encoder.layer.6.attention.output.LayerNorm.gamma', 'bert.encoder.layer.6.output.LayerNorm.beta', 'bert.encoder.layer.6.output.LayerNorm.gamma', 'bert.encoder.layer.7.attention.output.LayerNorm.beta', 'bert.encoder.layer.7.attention.output.LayerNorm.gamma', 'bert.encoder.layer.7.output.LayerNorm.beta', 'bert.encoder.layer.7.output.LayerNorm.gamma', 'bert.encoder.layer.8.attention.output.LayerNorm.beta', 'bert.encoder.layer.8.attention.output.LayerNorm.gamma', 'bert.encoder.layer.8.output.LayerNorm.beta', 'bert.encoder.layer.8.output.LayerNorm.gamma', 'bert.encoder.layer.9.attention.output.LayerNorm.beta', 'bert.encoder.layer.9.attention.output.LayerNorm.gamma', 'bert.encoder.layer.9.output.LayerNorm.beta', 'bert.encoder.layer.9.output.LayerNorm.gamma', 'bert.encoder.layer.10.attention.output.LayerNorm.beta', 'bert.encoder.layer.10.attention.output.LayerNorm.gamma', 'bert.encoder.layer.10.output.LayerNorm.beta', 'bert.encoder.layer.10.output.LayerNorm.gamma', 'bert.encoder.layer.11.attention.output.LayerNorm.beta', 'bert.encoder.layer.11.attention.output.LayerNorm.gamma', 'bert.encoder.layer.11.output.LayerNorm.beta', 'bert.encoder.layer.11.output.LayerNorm.gamma'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6214821338653564, 'eval_accuracy': 0.7658536585365854, 'eval_f1_macro': 0.7429289824988615, 'eval_f1_weighted': 0.765827559411305, 'eval_runtime': 5.5355, 'eval_samples_per_second': 777.704, 'eval_steps_per_second': 12.284, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6879e07653a4d38ba7ad0d3b7ad64c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfa8268b6784a6db78deced6e8b6f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531183a308e74cb69d064d1603c61b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf49de8654b4c019ce95c8bfb9fc615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec88e54bbf0e47228af142834bc098b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ning_v1/training_args.bin: 100%|##########| 5.26kB / 5.26kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e733fb78a30b4101b1dfa1f4d6030336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ning_v1/model.safetensors:  10%|9         | 41.9MB /  438MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b5697a83bc4d7a88fc996762b4a42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49ed8bf75e44df6aefa7dd4c7b53996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9135baf7a70477e9a1ef4eeef546b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eeb995a17fa424da7b22d92ceb184b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ning_v1/training_args.bin: 100%|##########| 5.26kB / 5.26kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419bc455c51248679bcebe277727b2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ning_v1/model.safetensors:  10%|9         | 41.9MB /  438MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ADS509/best_hp_tuning_v1/commit/31f095f7f0b1ccb97a79cc3ae1e7c24cbf200b3f', commit_message='Best model from HP search (f1_macro=0.7489)', commit_description='', oid='31f095f7f0b1ccb97a79cc3ae1e7c24cbf200b3f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ADS509/best_hp_tuning_v1', endpoint='https://huggingface.co', repo_type='model', repo_id='ADS509/best_hp_tuning_v1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain with best hyperparameters from hyperparameter_search and push to Hub\n",
    "repo_id = \"best_hp_tuning_v1\"\n",
    "\n",
    "label2id = {\"Argumentative\": 0, \"Expressive\": 1, \"Informational\": 2, \"Neutral\": 3, \"Opinion\": 4}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=5,\n",
    "    device_map='cuda',\n",
    "    dtype='auto',\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")\n",
    "\n",
    "best_hp = best_run.hyperparameters\n",
    "best_args = TrainingArguments(\n",
    "    output_dir=f'./best-{repo_id}',\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=f\"ADS509/{repo_id}\",\n",
    "    optim=best_hp['optimizer'],\n",
    "    num_train_epochs=best_hp['epochs'],\n",
    "    per_device_train_batch_size=best_hp['batch_size'],\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=best_hp['lr'],\n",
    "    weight_decay=best_hp['decay'],\n",
    "    warmup_steps=best_hp['warmup'],\n",
    "\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_macro',\n",
    "\n",
    "    logging_steps=100,\n",
    "    report_to='tensorboard',\n",
    "\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "best_trainer = Trainer(\n",
    "    model=best_model,\n",
    "    args=best_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "best_trainer.train()\n",
    "eval_results = best_trainer.evaluate()\n",
    "print(eval_results)\n",
    "\n",
    "best_trainer.save_model(best_args.output_dir)\n",
    "best_trainer.push_to_hub(commit_message=f\"Best model from HP search (f1_macro={best_run.objective:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS-509_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
