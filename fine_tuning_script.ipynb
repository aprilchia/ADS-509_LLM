{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f26c9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "os.environ[\"TENSORBOARD_LOGGING_DIR\"] = \"./logs\"\n",
    "\n",
    "MODEL_ID = 'bert-base-uncased'\n",
    "\n",
    "# check for gpu\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4628fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset you're using, don't forget to specify the data directory\n",
    "dataset = load_dataset('ADS509/final_project_data', data_dir=\"\")"
   "id": "27aeab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your hugging face token to log in\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4628fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a311f10a83774c6b8b1e4c655229ee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c248706c3d954c908e3f07077f28dd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f687f8d89ecb45d4b93759e914b6023b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d7650ac764491b8caae9b29c14475a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d891e44e49e84ee4bbfec6e00b9aea2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20089 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc4045f1ad54cc69f51eeb94586529f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dab1e729cca4ba286ce1f773e012f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['label', 'input_ids', 'attention_mask'])\n",
      "Input IDs shape: torch.Size([4, 512])\n",
      "Labels shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset you're using, don't forget to specify the data directory\n",
    "dataset = load_dataset('ADS509/final_project_data', data_dir=\"experiment-labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7062c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a311f10a83774c6b8b1e4c655229ee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c248706c3d954c908e3f07077f28dd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f687f8d89ecb45d4b93759e914b6023b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d7650ac764491b8caae9b29c14475a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d891e44e49e84ee4bbfec6e00b9aea2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20089 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc4045f1ad54cc69f51eeb94586529f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dab1e729cca4ba286ce1f773e012f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['label', 'input_ids', 'attention_mask'])\n",
      "Input IDs shape: torch.Size([4, 512])\n",
      "Labels shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Function to tokenize data with\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        truncation=True, \n",
    "        padding='max_length',\n",
    "       # max_length=128 # Can't be greater than model max length\n",
    "    )\n",
    "# Data collator handles padding dynamically, set padding and max_length if you want to control it explicitly and drop the collator\n",
    "\n",
    "# Tokenize Data\n",
    "train_data = dataset['train'].map(tokenize_function, batched=True)\n",
    "test_data = dataset['test'].map(tokenize_function, batched=True)\n",
    "valid_data = dataset['validation'].map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert lists to tensors\n",
    "train_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "test_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "valid_data.set_format(\"torch\", columns=['input_ids', \"attention_mask\", \"label\"])\n",
    "\n",
    "    \n",
    "# Verify batch\n",
    "test_loader = DataLoader(train_data, batch_size=4)\n",
    "batch = next(iter(test_loader))\n",
    "print(f\"Batch keys: {batch.keys()}\")\n",
    "print(f\"Input IDs shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Labels shape: {batch['label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbede08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a repo name to save the trained model to\n",
    "model_repo = \"experiment_labels_4epochs\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=5, # adjust this based on number of labels you're training on\n",
    "    device_map='cuda',\n",
    "    dtype='auto',\n",
    "    #label2id={}, # set these two args to attach the metadata to the model.config\n",
    "    #id2label={}\n",
    ")\n",
    "\n",
    "# Metric function for evaluation in Trainer\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'f1_macro': f1_score(labels, predictions, average='macro'),\n",
    "        'f1_weighted': f1_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "\n",
    "# Data collator to handle padding dynamically per batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./bert-comment-classifier', # Saves it locally\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=f\"ADS509/{model_repo}\",\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=200,  # or warmup_ratio=%\n",
    "    \n",
    "    # Evaluation & saving\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=100,\n",
    "    report_to='tensorboard',\n",
    "    \n",
    "    # Other\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision if GPU available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train!\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model to hugging face model repo\n",
    "trainer.save_model(training_args.output_dir)\n",
    "trainer.push_to_hub(commit_message = \"Bert based trained on original dataset with 4 epochs instead of 4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
